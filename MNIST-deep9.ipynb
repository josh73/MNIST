{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [Deep MNIST for Experts](https://www.tensorflow.org/versions/r1.2/get_started/mnist/pros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A deep MNIST classifier using convolutional layers.\n",
    "\n",
    "See extensive documentation at\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\"\"\"\n",
    "# Disable linter warnings to maintain consistency with tutorial.\n",
    "# pylint: disable=invalid-name\n",
    "# pylint: disable=g-bad-import-order\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define basic blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "    W = tf.Variable(tf.truncated_normal([5, 5, channels_in, channels_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.zeros([channels_out]), name=\"b\")\n",
    "    conv = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME', name=\"conv2d\")\n",
    "    act  = tf.nn.relu(conv + b, name='act')\n",
    "    max_pool = tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=\"max_pool\")\n",
    "    tf.summary.histogram(\"weights\", W)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "    return max_pool\n",
    "\n",
    "def fc_layer(input, channels_in, channels_out, name='fc'):\n",
    "  with tf.name_scope(name):\n",
    "    W = tf.Variable(tf.truncated_normal([channels_in, channels_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.zeros([channels_out]), name=\"b\")\n",
    "    logits = tf.matmul(input, W) + b\n",
    "    tf.summary.histogram(\"weights\", W)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"logits\", logits)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "  \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "\n",
    "  Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "    number of pixels in a standard MNIST image.\n",
    "\n",
    "  Returns:\n",
    "    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "    dropout.\n",
    "  \"\"\"\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - there is only one here, since images are\n",
    "  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "  x_image = tf.reshape(x, [-1, 28, 28, 1], name=\"x_image\")\n",
    "  tf.summary.image('input', x_image, 10)\n",
    "\n",
    "  conv1      = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "  conv2      = conv_layer(conv1,  32, 64, \"conv2\")\n",
    "  flattened  = tf.reshape(conv2, [-1, 7*7*64])\n",
    "  fc1_logits = fc_layer(flattened, 7*7*64, 1024, \"fc1_logits\")\n",
    "  fc1_act    = tf.nn.relu(fc1_logits, name=\"fc1_act\")\n",
    "\n",
    "  keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "  drop = tf.nn.dropout(fc1_act, keep_prob, name=\"drop\")\n",
    "\n",
    "  fc2_logits = fc_layer(drop, 1024, 10, \"fc2_logits\")\n",
    "\n",
    "  return fc2_logits, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784], name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, [None, 10], name=\"y_\")\n",
    "y_conv, keep_prob = deepnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.15625\n",
      "step 100, training accuracy 0.84375\n",
      "step 200, training accuracy 0.9375\n",
      "step 300, training accuracy 0.984375\n",
      "step 400, training accuracy 0.96875\n",
      "step 500, training accuracy 0.96875\n",
      "step 600, training accuracy 0.96875\n",
      "step 700, training accuracy 0.9375\n",
      "step 800, training accuracy 0.96875\n",
      "step 900, training accuracy 0.984375\n",
      "step 1000, training accuracy 0.984375\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"cross_entropy\"):\n",
    "  cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv), name=\"cross_entropy\")\n",
    "  tf.summary.scalar(\"cross_entropy\", tf.squeeze(cross_entropy))\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "  train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy, name=\"train_step\")\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "  correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1), name=\"correct_prediction\")\n",
    "  #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "  total_correct = tf.reduce_sum(tf.cast(correct_prediction, tf.float32), name=\"total_correct\")\n",
    "  total_in_batch = tf.cast(tf.shape(correct_prediction), tf.float32,name=\"total_in_batch\")\n",
    "  calc_accuracy = total_correct / total_in_batch\n",
    "  tf.summary.scalar(\"calc_accuracy\", tf.squeeze(calc_accuracy))\n",
    "\n",
    "# Set up forusing GPU\n",
    "config=tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"output1\")\n",
    "writer.add_graph(sess.graph)\n",
    "for i in range(1001):\n",
    "  x_train, y_train = mnist.train.next_batch(64)\n",
    "  if i % 100 == 0:\n",
    "    calc_acc = sess.run(\n",
    "        calc_accuracy, \n",
    "        feed_dict={x: x_train, y_: y_train, keep_prob: 1.0})\n",
    "    print('step %d, training accuracy %g' % (i, calc_acc))\n",
    "  if i % 5 == 0:\n",
    "    s=sess.run(merged_summary, feed_dict={x: x_train, y_: y_train, keep_prob: 1.0})\n",
    "    writer.add_summary(s, i)\n",
    "  sess.run(train_step, feed_dict={x: x_train, y_: y_train, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:(64, 784)\n",
      "train images shape: (55000, 784)\n",
      "test images shape: (10000, 784)\n",
      "(64, 784)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "  print(\"x_train shape:\" + str(x_train.shape))\n",
    "  print(\"train images shape: \" + str(mnist.train.images.shape))\n",
    "  print(\"test images shape: \" + str(mnist.test.images.shape))\n",
    "  x_test, y_test = mnist.test.next_batch(64)\n",
    "  print(x_test.shape)\n",
    "  print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_test_vectors: 10000\n",
      "num of minibatches = 157\n",
      "test accuracy 0.971537\n"
     ]
    }
   ],
   "source": [
    "test_minibatch_size = 64\n",
    "num_of_test_vectors = mnist.test.images.shape[0]\n",
    "print(\"num_of_test_vectors: \" + str(num_of_test_vectors))\n",
    "num_of_test_minibatches = math.ceil(num_of_test_vectors / test_minibatch_size)\n",
    "print(\"num of minibatches = \" + str(num_of_test_minibatches))\n",
    "\n",
    "total, correct = 0, 0\n",
    "for _ in range(num_of_test_minibatches):\n",
    "    x_test, y_test = mnist.test.next_batch(test_minibatch_size)\n",
    "    batch_total, batch_correct = sess.run([total_in_batch, total_correct], feed_dict={\n",
    "          x: x_test, y_: y_test, keep_prob: 1.0})\n",
    "    total += batch_total\n",
    "    correct += batch_correct\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print('test accuracy %g' % (test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d1680108c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcv2cpu",
   "language": "python",
   "name": "tfcv2cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
